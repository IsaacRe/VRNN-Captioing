{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import nltk\n",
    "import matplotlib as plt\n",
    "import numpy as np \n",
    "import argparse\n",
    "import pickle \n",
    "import os\n",
    "from torch.autograd import Variable \n",
    "from torchvision import transforms \n",
    "from build_vocab import Vocabulary\n",
    "from model_new import EncoderCNN, DecoderRNN\n",
    "from PIL import Image\n",
    "from data_loader import CocoDataset\n",
    "from collections import Counter\n",
    "from pycocotools.coco import COCO\n",
    "from step_1 import encode,decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, volatile=volatile)\n",
    "\n",
    "def load_image(image_path, transform=None):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize([224, 224], Image.LANCZOS)\n",
    "    \n",
    "    if transform is not None:\n",
    "        image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                             (0.229, 0.224, 0.225))])\n",
    "with open('./data/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "# Build Models\n",
    "encoder = EncoderCNN(256)\n",
    "encoder.eval()  # evaluation mode (BN uses moving mean/variance)\n",
    "decoder = DecoderRNN(256, 512, \n",
    "                     len(vocab), 1)\n",
    "\n",
    "# Load the trained model parameters\n",
    "encoder.load_state_dict(torch.load('./models/encoder_pretrained.pkl'))\n",
    "decoder.load_state_dict(torch.load('./models/decoder_pretrained.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/b3pang/anaconda2/lib/python2.7/site-packages/torch/backends/cudnn/__init__.py:48: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "image_id = \"1\"\n",
    "image = load_image('data/step_1/image_'+image_id+'.jpg', transform)\n",
    "image_tensor = to_var(image, volatile=True)\n",
    "# If use gpu\n",
    "if torch.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = encoder(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> a plane flying through the air with a sky background <end>\n",
      "<start> a plane flying through the air with a sky background <end>\n"
     ]
    }
   ],
   "source": [
    "pred,predu = decode(feature,vocab.word2idx['<start>'],decoder,vocab, c_step=2.0,prop_step=-1)\n",
    "print pred\n",
    "print predu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4525, 1673]\n",
      "******\n",
      "2\n",
      "******\n",
      "2\n",
      "******\n",
      "1\n",
      "<pad> <pad> <pad> are parked in a field with a sky background <end>\n",
      "<pad> <pad> <pad> are parked in a field with a sky background <end>\n"
     ]
    }
   ],
   "source": [
    "teach_wordid = ['<start>','several','planes']\n",
    "print [vocab.word2idx[word] for word in teach_wordid]\n",
    "pred,predu = decode(feature,[vocab.word2idx[word] for word in teach_wordid],decoder,vocab, c_step=2.0,prop_step=-1)\n",
    "print pred\n",
    "print predu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import DecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19a0829ad35f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mteach_wordid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'several'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'planes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mteach_wordid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprop_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mpredu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decode' is not defined"
     ]
    }
   ],
   "source": [
    "teach_wordid = ['<start>','several','planes']\n",
    "pred,predu = decode(feature,[vocab.word2idx[word] for word in teach_wordid],decoder,vocab, c_step=2.0,prop_step=-1)\n",
    "print pred\n",
    "print predu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -6.6667 -6.6667 -6.6667 -6.6667 -6.6667\n",
      " -6.6667 -6.6667 -6.6667 -6.6667 -6.6667\n",
      " -6.6667 -6.6667 -6.6667 -6.6667 -6.6667\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n",
      "Variable containing:\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True)\n",
    "print input.grad\n",
    "target = Variable(input.data+2)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print input.grad\n",
    "input.grad.data.zero_()\n",
    "print input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.7598  2.8590  0.9656  1.5102  3.7906\n",
       " 0.7517  1.2949  0.6209  1.3271  0.7654\n",
       " 0.5926  2.5933  1.2873  3.1093  2.4338\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
